import cv2
import numpy as np
import os
import pickle

# Initialize video capture and face detection model
video = cv2.VideoCapture(0)
facedetect = cv2.CascadeClassifier("haarcascade_frontalface_default.xml")

face_data = []

# Get name input from user
name = input("Enter your name:")

# Ensure the data directory exists
if not os.path.exists('data'):
    os.makedirs('data')

while True:
    ret, frame = video.read()
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    
    # Detect faces in the frame
    faces = facedetect.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)

    for (x, y, w, h) in faces:
        crop_img = frame[y:y+h, x:x+w]
        resized_img = cv2.resize(crop_img, (50, 50))
        face_data.append(resized_img)

        # Display the face count on the frame
        cv2.putText(frame, str(len(face_data)), org=(50, 50), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1, color=(50, 50, 255), thickness=1)
        
        # Draw rectangle around detected face
        cv2.rectangle(frame, (x, y), (x+w, y+h), (50, 50, 255), 1)
    
    # Show the frame
    cv2.imshow("Frame", frame)

    # Break loop if 100 faces are collected
    k = cv2.waitKey(1)
    if len(face_data) == 100:
        break

video.release()
cv2.destroyAllWindows()

# Reshaping the face data to have consistent number of samples and features
face_data = np.array(face_data)
face_data = face_data.reshape(100, -1)

# Saving name and face data using pickle
if 'names.pkl' not in os.listdir('data/'):
    names = [name] * 100
    with open('data/names.pkl', 'wb') as f:
        pickle.dump(names, f)
else:
    with open('data/names.pkl', 'rb') as f:
        names = pickle.load(f)
    names += [name] * 100

    with open('data/names.pkl', 'wb') as f:
        pickle.dump(names, f)

# Saving face data
if 'faces_data.pkl' not in os.listdir('data/'):
    with open('data/faces_data.pkl', 'wb') as f:
        pickle.dump(face_data, f)
else:
    with open('data/faces_data.pkl', 'rb') as f:
        faces = pickle.load(f)
    faces = np.append(faces, face_data, axis=0)

    with open('data/faces_data.pkl', 'wb') as f:
        pickle.dump(faces, f)

----------------------------------
db_connection 

import cv2
import numpy as np
import os
import mysql.connector
import pickle

# Initialize database connection
conn = mysql.connector.connect(host="localhost", user="root", password="15052003", database="FaceRecognition")
cursor = conn.cursor()

# Initialize video capture and face detection
video = cv2.VideoCapture(0)
facedetect = cv2.CascadeClassifier("haarcascade_frontalface_default.xml")

name = input("Enter your name: ")

face_data = []

while True:
    ret, frame = video.read()
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    faces = facedetect.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)

    for (x, y, w, h) in faces:
        crop_img = frame[y:y+h, x:x+w]
        resized_img = cv2.resize(crop_img, (50, 50))
        face_data.append(resized_img)

        cv2.putText(frame, str(len(face_data)), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (50, 50, 255), 1)
        cv2.rectangle(frame, (x, y), (x+w, y+h), (50, 50, 255), 1)

    cv2.imshow("Frame", frame)

    if len(face_data) == 100:
        break

video.release()
cv2.destroyAllWindows()

# Convert face data to binary
face_data_np = np.array(face_data)
face_data_bytes = pickle.dumps(face_data_np)

# Insert into database
cursor.execute("INSERT INTO faces (name, face_data) VALUES (%s, %s)", (name, face_data_bytes))
conn.commit()

print(f"Face data for {name} stored in the database.")

cursor.close()
conn.close()




-------------------

complete code 

import cv2
import numpy as np
import os
import mysql.connector
import pickle

# Initialize database connection
conn = mysql.connector.connect(host="localhost", user="root", password="15052003", database="FaceRecognition")
cursor = conn.cursor()

# Initialize video capture and face detection
video = cv2.VideoCapture(0)
facedetect = cv2.CascadeClassifier("haarcascade_frontalface_default.xml")

name = input("Enter your name: ")

face_data = []

while True:
    ret, frame = video.read()
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    faces = facedetect.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)

    for (x, y, w, h) in faces:
        crop_img = frame[y:y+h, x:x+w]
        resized_img = cv2.resize(crop_img, (50, 50))
        face_data.append(resized_img)

        cv2.putText(frame, str(len(face_data)), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (50, 50, 255), 1)
        cv2.rectangle(frame, (x, y), (x+w, y+h), (50, 50, 255), 1)

    cv2.imshow("Frame", frame)

    if len(face_data) == 100:
        break

video.release()
cv2.destroyAllWindows()

# Convert face data to binary
face_data_np = np.array(face_data)
face_data_bytes = pickle.dumps(face_data_np)

# Insert into database
cursor.execute("INSERT INTO faces (name, face_data) VALUES (%s, %s)", (name, face_data_bytes))
conn.commit()

print(f"Face data for {name} stored in the database.")

cursor.close()
conn.close()


----------------------------------------------------------------------------------------------------------------------------------
import cv2
import numpy as np
import os
import mysql.connector
import pickle

# Initialize database connection
conn = mysql.connector.connect(host="localhost", user="root", password="15052003", database="FaceRecognition")
cursor = conn.cursor()

# Initialize video capture and face detection
video = cv2.VideoCapture(0)
facedetect = cv2.CascadeClassifier("haarcascade_frontalface_default.xml")

name = input("Enter your name: ")

face_data = []

while True:
    ret, frame = video.read()
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    faces = facedetect.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)

    for (x, y, w, h) in faces:
        crop_img = frame[y:y+h, x:x+w]
        resized_img = cv2.resize(crop_img, (50, 50))
        face_data.append(resized_img)

        cv2.putText(frame, str(len(face_data)), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (50, 50, 255), 1)
        cv2.rectangle(frame, (x, y), (x+w, y+h), (50, 50, 255), 1)

    cv2.imshow("Frame", frame)

    if len(face_data) == 100:
        break

video.release()
cv2.destroyAllWindows()

# Convert face data to binary
face_data_np = np.array(face_data)
face_data_bytes = pickle.dumps(face_data_np)

# Insert into database
cursor.execute("INSERT INTO faces (name, face_data) VALUES (%s, %s)", (name, face_data_bytes))
conn.commit()

print(f"Face data for {name} stored in the database.")

cursor.close()
conn.close()









# import cv2
# import numpy as np
# import mysql.connector
# import pickle
# from flask import jsonify

# def capture_face_data(name):
#     # Initialize database connection
#     conn = mysql.connector.connect(host="localhost", user="root", password="15052003", database="FaceRecognition")
#     cursor = conn.cursor()

#     # Initialize video capture and face detection
#     video = cv2.VideoCapture(0)
#     facedetect = cv2.CascadeClassifier("haarcascade_frontalface_default.xml")

#     face_data = []

#     while len(face_data) < 5:  # Capture 100 images for face data
#         ret, frame = video.read()
#         gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
#         faces = facedetect.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)

#         for (x, y, w, h) in faces:
#             crop_img = frame[y:y+h, x:x+w]
#             resized_img = cv2.resize(crop_img, (50, 50))
#             face_data.append(resized_img)

#         cv2.putText(frame, str(len(face_data)), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (50, 50, 255), 1)
#         cv2.rectangle(frame, (x, y), (x+w, y+h), (50, 50, 255), 1)

#     video.release()
#     cv2.destroyAllWindows()

#     # Convert face data to binary
#     face_data_np = np.array(face_data)
#     face_data_bytes = pickle.dumps(face_data_np)

#     # Insert into database
#     cursor.execute("INSERT INTO faces (name, face_data) VALUES (%s, %s)", (name, face_data_bytes))
#     conn.commit()

#     cursor.close()
#     conn.close()

#     return jsonify({"message": f"Face data for {name} stored in the database."}), 200

# import cv2
# import numpy as np
# import mysql.connector
# import pickle
# from flask import jsonify

# def capture_face_data(name):
#     # Initialize database connection
#     conn = mysql.connector.connect(host="localhost", user="root", password="15052003", database="FaceRecognition")
#     cursor = conn.cursor()

#     # Initialize video capture and face detection
#     video = cv2.VideoCapture(0)
#     facedetect = cv2.CascadeClassifier("haarcascade_frontalface_default.xml")

#     face_data = []

#     while len(face_data) < 5:  # Capture 5 images for face data
#         ret, frame = video.read()
#         gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
#         faces = facedetect.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)

#         for (x, y, w, h) in faces:
#             crop_img = frame[y:y+h, x:x+w]
#             resized_img = cv2.resize(crop_img, (50, 50))
#             face_data.append(resized_img)

#         cv2.putText(frame, str(len(face_data)), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (50, 50, 255), 1)
#         cv2.rectangle(frame, (x, y), (x+w, y+h), (50, 50, 255), 1)

#     video.release()
#     cv2.destroyAllWindows()

#     # Convert face data to binary
#     face_data_np = np.array(face_data)
#     face_data_bytes = pickle.dumps(face_data_np)

#     # Insert into database
#     cursor.execute("INSERT INTO faces (name, face_data) VALUES (%s, %s)", (name, face_data_bytes))
#     conn.commit()

#     cursor.close()
#     conn.close()

#     return jsonify({"message": f"Face data for {name} stored in the database."}), 200


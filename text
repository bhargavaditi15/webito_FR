dataset 

import cv2
import numpy as np
import os
import pickle

# Initialize video capture and face detection model
video = cv2.VideoCapture(0)
facedetect = cv2.CascadeClassifier("haarcascade_frontalface_default.xml")

face_data = []

# Get name input from user
name = input("Enter your name:")

# Ensure the data directory exists
if not os.path.exists('data'):
    os.makedirs('data')

while True:
    ret, frame = video.read()
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    
    # Detect faces in the frame
    faces = facedetect.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)

    for (x, y, w, h) in faces:
        crop_img = frame[y:y+h, x:x+w]
        resized_img = cv2.resize(crop_img, (50, 50))
        face_data.append(resized_img)

        # Display the face count on the frame
        cv2.putText(frame, str(len(face_data)), org=(50, 50), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1, color=(50, 50, 255), thickness=1)
        
        # Draw rectangle around detected face
        cv2.rectangle(frame, (x, y), (x+w, y+h), (50, 50, 255), 1)
    
    # Show the frame
    cv2.imshow("Frame", frame)

    # Break loop if 100 faces are collected
    k = cv2.waitKey(1)
    if len(face_data) == 100:
        break

video.release()
cv2.destroyAllWindows()

# Reshaping the face data to have consistent number of samples and features
face_data = np.array(face_data)
face_data = face_data.reshape(100, -1)

# Saving name and face data using pickle
if 'names.pkl' not in os.listdir('data/'):
    names = [name] * 100
    with open('data/names.pkl', 'wb') as f:
        pickle.dump(names, f)
else:
    with open('data/names.pkl', 'rb') as f:
        names = pickle.load(f)
    names += [name] * 100

    with open('data/names.pkl', 'wb') as f:
        pickle.dump(names, f)

# Saving face data
if 'faces_data.pkl' not in os.listdir('data/'):
    with open('data/faces_data.pkl', 'wb') as f:
        pickle.dump(face_data, f)
else:
    with open('data/faces_data.pkl', 'rb') as f:
        faces = pickle.load(f)
    faces = np.append(faces, face_data, axis=0)

    with open('data/faces_data.pkl', 'wb') as f:
        pickle.dump(faces, f)


attendance

import cv2
import numpy as np
import os
import csv
import time
import pickle
from sklearn.neighbors import KNeighborsClassifier
from datetime import datetime

# Initialize video capture and face detection model
video = cv2.VideoCapture(0)
facedetect = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')

# Ensure data directory exists
if not os.path.exists('data'):
    os.makedirs('data')

# Load labels and faces data
if os.path.exists('data/names.pkl'):
    with open('data/names.pkl', 'rb') as w:
        LABELS = pickle.load(w)
else:
    print("Error: names.pkl not found!")

if os.path.exists('data/faces_data.pkl'):
    with open('data/faces_data.pkl', 'rb') as f:
        FACES = pickle.load(f)
else:
    print("Error: faces_data.pkl not found!")

# Check if the number of faces and labels are consistent
if len(LABELS) != len(FACES):
    print(f"Error: Number of labels ({len(LABELS)}) does not match number of faces ({len(FACES)})")
    exit()

# Initialize the KNN classifier
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(FACES, LABELS)

# Column names for CSV file
COL_NAMES = ['NAME', 'TIME']

# Ensure Attendance directory exists
if not os.path.exists('Attendance'):
    os.makedirs('Attendance')

# Code to recognize faces and log attendance
while True:
    ret, frame = video.read()
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    faces = facedetect.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)

    for (x, y, w, h) in faces:
        crop_img = frame[y:y+h, x:x+w]
        resized_img = cv2.resize(crop_img, (50, 50)).flatten().reshape(1, -1)
        
        # Predict the person based on KNN classifier
        output = knn.predict(resized_img)
        
        ts = time.time()
        date = datetime.fromtimestamp(ts).strftime("%d-%m-%y")
        timestamp = datetime.fromtimestamp(ts).strftime("%H:%M:%S")
        
        # Check if the attendance file already exists
        exist = os.path.isfile(f"Attendance/Attendance_{date}.csv")
        
        # Draw rectangle around face and display name
        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 0), 1)
        cv2.rectangle(frame, (x, y), (x + w, y + h), (50, 50, 255), 2)
        cv2.rectangle(frame, (x, y - 40), (x + w, y), (50, 50, 255), -1)
        cv2.putText(frame, str(output[0]), (x, y - 10), cv2.FONT_HERSHEY_COMPLEX, 1, (50, 50, 255), 1)
        
        # Attendance data to save
        attendance = [str(output[0]), str(timestamp)]

    # Display the frame (no background image, just the live video)
    cv2.imshow("frame", frame)

    # Handle saving the attendance data when 'o' is pressed
    k = cv2.waitKey(1)
    if k == ord('o'):
        time.sleep(5)

        if exist:
            with open(f"Attendance/Attendance_{date}.csv", "a") as csvfile:
                writer = csv.writer(csvfile)
                writer.writerow(attendance)  # Write attendance record
        else:
            with open(f"Attendance/Attendance_{date}.csv", "a") as csvfile:
                writer = csv.writer(csvfile)
                writer.writerow(COL_NAMES)  # Write column headers
                writer.writerow(attendance)  # Write attendance record

    # Break loop when 'q' is pressed
    if k == ord('q'):
        break

# Release video capture and close OpenCV window
video.release()
cv2.destroyAllWindows()
